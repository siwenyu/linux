# 字符集的发展

### 第一阶段：ASCII
开始时候计算机只在美国使用，是由8个可以开合的晶体管组合成2的8次方=256中状态。美国人将0-20设置成控制码，之后又把空格，标点，数字，大小写字母等设置，一直编到了127，这样能满足美国英文情况下的需求。这就是原始的ASCII码，叫做 ANSI 的”Ascii”编码（American Standard Code for Information Interchange，美国信息互换标准代码）。
### 中国的GB2312、GBK、GB18030、DBCS
后来，其他国家开始使用计算机，并想保存自己的字母(非英文)，他们从128开始编自己需要的字母，还添加了字母，横线，竖线等字符，一直到255位(用完了，搞不搞？？)，这128-255之间的字符成为”拓展字符集”。

再后来，中国人登场了，博大精深的汉字你怕不怕？常规的有6000+需要保存。但是中国人民可不是吃素的，我们将128开始的拓展字符集全部干掉，并重新定义：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。不止如此，包括之前ASCII中存在的数字标点字母也都重新编成了两个字节的编码，这就有了我们所说的全角字符，而原来的127一下的字符就成为半角字符了。作为对ASCII的一种扩展，把这种汉字方案成为”GB2312”。

到这里就结束了吗？博大精深你怕不怕？汉字太多还是不够用，于是我们不再要求低字节必须是大于127的码，这样只要高字节大于127，我们就认为是汉字了，这个编码规则又增加了20000多汉字，这个编码方案叫做”GBK”。

这就完了？博大精深你怕不怕？中国的少数民族进步了，想传承中华文化，就又拓展了一些，成了”GB18030”,至此告一段落，中国的程序员们看到这一系列汉字编码的标准是好的，于是通称他们叫做 “DBCS“（Double Byte Charecter Set 双字节字符集）。于是一个汉字是两个英文字符，成了中国程序员的咒语。
### 统一
中国的搞完了，世界也是博大精深的好不？A想用B国的程序，就必须下载一套他们的字符解析系统，CDEFG。。。。。。。恩！
此时，一个伟大的国际组织出现了——ISO（国际标谁化组织），他们的做法简单粗暴：废除了所有的编码规则，重新搞一套通用的。叫做"USC"，也就是咱们使用的unicode编码。

计算机发展了，中文的双字节方式占空间大的问题不再是问题于是统一成所有字符全部使用双字节方式，原来的半角字符的高八位永远为0。这样如果是英文文本会浪费一般的存储空间。这样的话，一个字符就准确的是两个字节了，而一个汉字就是一个字符也就是两个字节，咒语对不上了。一个汉字算两个英文字符的时代过去了。

### UTF-8
至此，规范制定完了，但是如何推广大家使用是个难题。后来互联网的出现，网络传输规范出现了UTF-8(UCS Transfer Format)和UTF-16两种为解决传输问题出现的编码方式，UTF-8就是在互联网上使用最广的一种unicode的实现方式，UTF-8就是每次8个位传输数据，而UTF-16就是每次16个位这是为传输而设计的编码，并使编码无国界，这样就可以显示全世界上所有文化的字符了。
最终：出现了把Unicode编码转化为“可变长编码”的UTF-8编码。UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间。


